# Product Roadmap

## Guiding Principles

1. **Staged MVPs** - Launch small, learn, iterate
2. **Traction first** - Build user base before complex features
3. **Viral hooks** - Each MVP should have sharing/growth mechanics
4. **Experimentation** - Platform learns what works through variation
5. **User ladder** - Clear path from casual to deeply engaged

## Phase 1: Foundation (November - December 2025)

### Milestone: Launch Bullspin Detector
**Target**: November 2025

**What ships**:
- Simple web interface
- Text upload functionality
- AI analysis engine (detect partisan language, neutral language, nonsense)
- Visual highlighting of analysis results
- Shareable results (viral mechanics)

**Success criteria**:
- 250 users by end of December 2025
- Viral coefficient >1 (users invite others)
- Return rate >20% (users come back)

**What we learn**:
- Do people care about political BS detection?
- What makes them share results?
- What brings them back?

## Phase 2: Engagement (Q1 2026)

### Milestone: Proposal Feed + Political Spectrum Quiz

**What ships**:
- Political Spectrum Quiz (shareable, AI-powered)
- Feed of proposals uploaded by users
- Tinder-style like/dislike interface
- Notifications of new proposals
- User profiles (basic)

**Success criteria**:
- 1,000+ active users
- Weekly engagement (users return at least once/week)
- User-generated proposals being submitted
- Profile data for assembly selection

**What we learn**:
- Can we convert viral traffic to engaged users?
- What proposals do people care about?
- Who are the most engaged participants?

## Phase 3: Community Deliberation (Q2 2026)

### Milestone: Submit Proposals + AI Optimization

**What ships**:
- Proposal submission interface
- AI suggestions for increasing consensus potential
- Community feedback on proposals
- Upvoting/commenting (with emphasis on reasoning, not just reactions)
- "AI-optimized version" alongside original

**Success criteria**:
- 50+ proposals submitted per week
- Engagement with feedback (comments, reasoning)
- Proposals improve after AI + community input

**What we learn**:
- Can AI actually help find consensus language?
- Do people engage constructively?
- What topics generate most engagement?

## Phase 4: Citizens Assemblies (Q3-Q4 2026)

### Milestone: Assembly MVP

**What ships**:
- Availability indication (citizens say when they can participate)
- Selection algorithm (filter for neutrality, representativeness)
- Parameter assignment (random/suggested assembly formats)
- Assembly facilitation interface (sync/async debate)
- Consensus-building tools
- Final proposal output

**Success criteria**:
- 10+ assemblies completed
- >50% reach consensus
- High participant satisfaction
- Proposals demonstrably higher quality after deliberation

**What we learn**:
- What assembly formats work best?
- Can we actually reach consensus online?
- Do neutral participants produce better outcomes?
- Which randomized parameters correlate with success?

## Phase 5: Impact (2027)

### Milestone: Real-World Integration

**What ships**:
- Politician branded platforms (white-label Middling)
- Advocacy org data dashboards
- Tracking of proposals â†’ official political process
- Success stories and case studies
- Labor marketplace (compensated citizen work)

**Success criteria**:
- First proposals adopted by governments
- First paying customers (politicians, advocacy orgs)
- Proof of civic impact
- Path to sustainability

**What we learn**:
- Will politicians/orgs actually pay?
- Does citizen deliberation influence policy?
- What's the ROI for organizations?

## Key Dependencies

### Technical
- AI models for analysis (partisan detection, consensus optimization)
- Selection algorithms
- Assembly facilitation tools (sync/async, various formats)
- Data analytics for organizations

### User Base
- Critical mass for assemblies (likely 500-1000 users minimum)
- Geographic/demographic diversity
- Engaged citizens willing to deliberate (not just vote)

### Partnerships
- Local governments willing to try citizen proposals
- Advocacy orgs interested in data
- Politicians open to new constituent engagement

### Validation
- Proof that assemblies reach consensus
- Proof that proposals improve through deliberation
- Proof that citizen input influences policy

## Experiments to Run

### Assembly Format Variables
- Synchronous vs asynchronous (or % mix)
- Duration (3 days vs 3 weeks)
- Schedule (daily vs weekends only)
- Participant count (7 vs 15 vs 30)
- Facilitation style (AI-guided vs human moderator)

### Selection Variables
- Strictness of neutrality filter
- Representativeness requirements
- Expertise level (informed citizens vs experts)

### North Star Metric Optimization
- **Primary**: % of assemblies reaching consensus
- **Ultimate**: % of proposals adopted by official authorities

Track which variables correlate with success.

## Flexibility Built In

**What might change**:
- Timeline (faster or slower based on traction)
- Feature priority (skip phases if user behavior suggests different path)
- Target market (might find traction in unexpected jurisdictions)
- Revenue model (might discover new willingness to pay)

**What won't change**:
- Citizens always free
- Optimize for consensus, not engagement
- Experimentation with democratic formats
- Focus on real civic impact

## Long-Term Vision (5+ years)

- Used in dozens of countries
- Thousands of assemblies completed
- Measurable improvement in civic trust
- Template for 21st century democracy
- Proof that online deliberation works
- Alternative to social media political dysfunction
